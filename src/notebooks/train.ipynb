{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90130343",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# modules\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler \n",
    "from torchvision.transforms import Normalize\n",
    "from albumentations import Compose, OneOf, ShiftScaleRotate, HorizontalFlip\n",
    "from albumentations.augmentations import transforms as aug\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "\n",
    "# utils.\n",
    "from utils import util\n",
    "from utils.config import Config\n",
    "import factory\n",
    "from utils.cutmix_mixup import cutmix, mixup, cutmix_soft_label, mixup_soft_label\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf60da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hirano/work/Competition/Nishika_cable/src\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hirano/work/Competition/Nishika_cable/src/\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df92804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Nishika_cable')\n",
    "parser.add_argument('--config', default='config/040.py')#,required=True)\n",
    "parser.add_argument('--fold', default='4', type=int)#, required=True)\n",
    "parser.add_argument('--gpu', default='0', type=int)#, required=True)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6ce24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make output dir /home/hirano/work/Competition/Nishika_cable/output/040/4\n"
     ]
    }
   ],
   "source": [
    "# make output_dir if needed.\n",
    "cfg = Config.fromfile(args.config)\n",
    "cfg.fold = args.fold\n",
    "cfg.working_dir = cfg.output_dir / cfg.version / str(cfg.fold)\n",
    "\n",
    "util.make_output_dir_if_needed(cfg.working_dir)\n",
    "print('Make output dir {}'.format(cfg.working_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2a00c9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Runner:\n",
    "    def __init__(self, cfg, model, criterion, optimizer, scheduler, device, logger):\n",
    "        self.cfg = cfg\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.logger = logger\n",
    "\n",
    "    def train(self, dataset_trn, dataset_val, loader_trn, loader_val):\n",
    "        print(f'training start at {datetime.datetime.now()}')\n",
    "\n",
    "        self.cfg.snapshot.output_dir = self.cfg.working_dir / 'weight'\n",
    "        snap = util.Snapshot(**self.cfg.snapshot)\n",
    "\n",
    "        self.use_mixup = self.cfg.use_mixup_cutmix\n",
    "        \n",
    "        for epoch in range(self.cfg.n_epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            if epoch >= self.cfg.wo_mixup_epochs:\n",
    "                self.use_mixup = False\n",
    "\n",
    "            # train.\n",
    "            if self.cfg.with_soft_label:\n",
    "                result_trn = self.run_nn_with_soft_label('trn', dataset_trn, loader_trn)\n",
    "            else:    \n",
    "                result_trn = self.run_nn('trn', dataset_trn, loader_trn)\n",
    "\n",
    "            # valid.\n",
    "            with torch.no_grad():\n",
    "                if self.cfg.with_soft_label:\n",
    "                    result_val = self.run_nn_with_soft_label('val', dataset_val, loader_val)\n",
    "                else:\n",
    "                    result_val = self.run_nn('val', dataset_val, loader_val)\n",
    "\n",
    "            # scheduler step.\n",
    "            if self.scheduler.__class__.__name__=='ReduceLROnPlateau':\n",
    "                self.scheduler.step(result_val[self.cfg.scheduler.monitor])\n",
    "            else:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            wrap_time = time.time()-start_time\n",
    "\n",
    "            # logging.\n",
    "            logging_info = [epoch+1, wrap_time]\n",
    "            logging_info.extend(sum([[result_trn[i], result_val[i]] for i in self.cfg.logger.params.logging_info], []))\n",
    "            if self.logger:\n",
    "                self.logger.write_log(logging_info)\n",
    "\n",
    "            print(f\"{epoch+1}/{self.cfg.n_epochs}: trn_loss={result_trn['loss']:.4f}, val_loss={result_val['loss']:.4f}, val_metric={result_val['metric']:.4f}, time={wrap_time:.2f}sec\")\n",
    "\n",
    "            # snapshot.\n",
    "            snap.snapshot(result_val[self.cfg.snapshot.monitor], self.model, self.optimizer, epoch)\n",
    "\n",
    "    def test(self, dataset_test, loader_test):\n",
    "        print(f'test start at {datetime.datetime.now()}')\n",
    "        with torch.no_grad():\n",
    "            if self.cfg.with_soft_label:\n",
    "                result = self.run_nn_with_soft_label('test', dataset_test, loader_test)\n",
    "            else:\n",
    "                result = self.run_nn('test', dataset_test, loader_test)\n",
    "        print('done.')\n",
    "        return result\n",
    "\n",
    "    def run_nn(self, mode, dataset, loader):\n",
    "\n",
    "        losses = []\n",
    "        metrics = 0\n",
    "        \n",
    "        #sm = torch.nn.Sigmoid()\n",
    "\n",
    "        if self.cfg.use_amp:\n",
    "            scaler = GradScaler()\n",
    "\n",
    "        if mode=='trn':\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            val_pred = np.zeros((len(dataset)))\n",
    "            val_target = np.zeros(len(dataset))\n",
    "\n",
    "        for idx, batch in enumerate(tqdm(loader)):\n",
    "            img    = batch['image']\n",
    "            target = batch['target']\n",
    "\n",
    "            img   = img.to(self.device, dtype=torch.float)\n",
    "            label = target.to(self.device, dtype=torch.long)#float)\n",
    "\n",
    "            #if len(batch)>2:\n",
    "            #    soft_label = batch['soft_label']\n",
    "            #    soft_label = soft_label.to(self.device, dtype=torch.float)\n",
    "            \n",
    "            if mode=='trn' and self.use_mixup:\n",
    "                p = np.random.rand()\n",
    "                if 0.0<=p<self.cfg.mixup_freq/2:\n",
    "                    # apply mixup.\n",
    "                    img, results = mixup(img, label, self.cfg.mixup_alpha)\n",
    "                    if self.cfg.use_amp:\n",
    "                        with autocast():\n",
    "                            pred = self.model(img)\n",
    "                            loss = self.criterion.calc_mixloss(pred, results)\n",
    "                    else:\n",
    "                        pred = self.model(img)\n",
    "                        loss = self.criterion.calc_mixloss(pred, results)\n",
    "                elif self.cfg.mixup_freq/2<=p<self.cfg.mixup_freq: # note use.\n",
    "                    # apply cutmix.\n",
    "                    img, results = cutmix(img, label, self.cfg.cutmix_alpha)\n",
    "                    if self.cfg.use_amp:\n",
    "                        with autocast():\n",
    "                            pred = self.model(img)\n",
    "                            loss = self.criterion.calc_mixloss(pred, results)\n",
    "                    else:\n",
    "                        pred = self.model(img)\n",
    "                        loss = self.criterion.calc_mixloss(pred, results)\n",
    "\n",
    "                else:\n",
    "                    # wo mixup cutmix.\n",
    "                    if self.cfg.use_amp:\n",
    "                        with autocast():\n",
    "                            pred = self.model(img)\n",
    "                            loss = self.criterion.calc_loss(pred, label)\n",
    "                    else:\n",
    "                        pred = self.model(img)\n",
    "                        loss = self.criterion.calc_loss(pred, label)\n",
    "            else:\n",
    "                # pred and calc losses.\n",
    "                if self.cfg.use_amp:\n",
    "                    with autocast():\n",
    "                        pred = self.model(img)\n",
    "                        loss = self.criterion.calc_loss(pred, label)\n",
    "                else:\n",
    "                    pred = self.model(img)\n",
    "                    loss = self.criterion.calc_loss(pred, label)\n",
    "                \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if mode=='trn':\n",
    "                if self.cfg.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            else:\n",
    "                # make predictions.\n",
    "                #print(pred, pred.dtype, pred.size())\n",
    "                #print(pred.detach().softmax(1).cpu().squeeze().numpy())\n",
    "                val_pred[idx * self.cfg.batch_size:(idx + 1) * self.cfg.batch_size] += pred.detach().softmax(1).argmax(1).cpu().squeeze().numpy()\n",
    "                # targets.\n",
    "                val_target[idx * self.cfg.batch_size:(idx + 1) * self.cfg.batch_size] += label.detach().cpu().squeeze().numpy()\n",
    "\n",
    "        if mode=='val':\n",
    "            # calc. metrics.\n",
    "            val_pred = np.nan_to_num(val_pred)\n",
    "            val_pred[val_pred ==-np.inf] = 0\n",
    "            val_pred[val_pred == np.inf] = 0\n",
    "            metrics = self.criterion.calc_metrics(val_pred, val_target)\n",
    "        elif mode=='test':\n",
    "            return val_pred      \n",
    "\n",
    "        result = dict(\n",
    "            loss=np.sum(losses)/len(loader),\n",
    "            metric=metrics,\n",
    "        )\n",
    "\n",
    "        return result\n",
    "\n",
    "    def run_nn_with_soft_label(self, mode, dataset, loader):\n",
    "\n",
    "        losses = []\n",
    "        metrics = 0\n",
    "        \n",
    "        #sm = torch.nn.Sigmoid()\n",
    "\n",
    "        if self.cfg.use_amp:\n",
    "            scaler = GradScaler()\n",
    "\n",
    "        if mode=='trn':\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            val_pred = np.zeros((len(dataset)))\n",
    "            val_target = np.zeros(len(dataset))\n",
    "\n",
    "        for idx, batch in enumerate(tqdm(loader)):\n",
    "            img    = batch['image']\n",
    "            target = batch['target']\n",
    "\n",
    "            img   = img.to(self.device, dtype=torch.float)\n",
    "            label = target.to(self.device, dtype=torch.float)\n",
    "\n",
    "            if len(batch)>2:\n",
    "                soft_label = batch['soft_label']\n",
    "                soft_label = soft_label.to(self.device, dtype=torch.float)\n",
    "            \n",
    "            if mode=='trn' and self.use_mixup:\n",
    "                p = np.random.rand()\n",
    "                if 0.0<=p<self.cfg.mixup_freq/2:\n",
    "                    # apply mixup.\n",
    "                    img, results = mixup_soft_label(img, [label, soft_label], self.cfg.mixup_alpha)\n",
    "                    if self.cfg.use_amp:\n",
    "                        with autocast():\n",
    "                            pred1, pred2 = self.model(img)\n",
    "                            loss = self.criterion.calc_mixloss([pred1, pred2], results)\n",
    "                    else:\n",
    "                        pred1, pred2 = self.model(img)\n",
    "                        loss = self.criterion.calc_mixloss([pred1, pred2], results)\n",
    "                elif self.cfg.mixup_freq/2<=p<self.cfg.mixup_freq: # note use.\n",
    "                    # apply cutmix.\n",
    "                    img, results = cutmix_soft_label(img, [label, soft_label], self.cfg.cutmix_alpha)\n",
    "                    if self.cfg.use_amp:\n",
    "                        with autocast():\n",
    "                            pred1, pred2 = self.model(img)\n",
    "                            loss = self.criterion.calc_mixloss([pred1, pred2], results)\n",
    "                    else:\n",
    "                        pred1, pred2 = self.model(img)\n",
    "                        loss = self.criterion.calc_mixloss([pred1, pred2], results)\n",
    "\n",
    "                else:\n",
    "                    # wo mixup cutmix.\n",
    "                    if self.cfg.use_amp:\n",
    "                        with autocast():\n",
    "                            pred1, pred2 = self.model(img)\n",
    "                            loss = self.criterion.calc_loss([pred1, pred2], [label, soft_label])\n",
    "                    else:\n",
    "                        pred1, pred2 = self.model(img)\n",
    "                        loss = self.criterion.calc_loss([pred1, pred2], [label, soft_label])\n",
    "            else:\n",
    "                # pred and calc losses.\n",
    "                if self.cfg.use_amp:\n",
    "                    with autocast():\n",
    "                        pred1, pred2 = self.model(img)\n",
    "                        loss = self.criterion.calc_loss([pred1, pred2], [label, soft_label])\n",
    "                else:\n",
    "                    pred1, pred2 = self.model(img)\n",
    "                    loss = self.criterion.calc_loss([pred1, pred2], [label, soft_label])\n",
    "                \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if mode=='trn':\n",
    "                if self.cfg.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            else:\n",
    "                # make predictions.\n",
    "                val_pred[idx * self.cfg.batch_size:(idx + 1) * self.cfg.batch_size] += pred1.detach().cpu().squeeze().numpy()\n",
    "                # targets.\n",
    "                val_target[idx * self.cfg.batch_size:(idx + 1) * self.cfg.batch_size] += label.detach().cpu().squeeze().numpy()\n",
    "\n",
    "        if mode=='val':\n",
    "            # calc. metrics.\n",
    "            val_pred = np.nan_to_num(val_pred)\n",
    "            #val_pred[val_pred ==-np.inf] = 0\n",
    "            #val_pred[val_pred == np.inf] = 0\n",
    "            metrics = self.criterion.calc_metrics(val_pred, val_target)\n",
    "        elif mode=='test':\n",
    "            return val_pred      \n",
    "\n",
    "        result = dict(\n",
    "            loss=np.sum(losses)/len(loader),\n",
    "            metric=metrics,\n",
    "        )\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce19b7c0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    args = util.get_args()\n",
    "    cfg = Config.fromfile(args.config)\n",
    "    cfg.fold = args.fold\n",
    "    \n",
    "    cfg.working_dir = cfg.output_dir / cfg.version / str(cfg.fold)\n",
    "\n",
    "    # make output_dir if needed.\n",
    "    util.make_output_dir_if_needed(cfg.working_dir)\n",
    "\n",
    "    # set logger.\n",
    "    cfg.logger.params.name = cfg.working_dir / f'history.csv'\n",
    "    my_logger = util.CustomLogger(**cfg.logger.params)\n",
    "\n",
    "    # set seed.\n",
    "    util.seed_everything(cfg.seed)\n",
    "\n",
    "    # get dataloader.\n",
    "    print(f'dataset: {cfg.dataset_name}')\n",
    "    folds = [fold for fold in range(cfg.n_fold) if cfg.fold != fold]\n",
    "    dataset_train, loader_train = factory.get_dataset_loader(cfg.train, folds)\n",
    "    dataset_valid, loader_valid = factory.get_dataset_loader(cfg.valid, [cfg.fold])\n",
    "\n",
    "    # get model.\n",
    "    print(f'model: {cfg.model.name}')\n",
    "    model = factory.get_model(cfg.model)\n",
    "    device = factory.get_device(args.gpu)\n",
    "    model.cuda()\n",
    "    model.to(device)\n",
    "\n",
    "    if cfg.num_gpu>1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # get optimizer.\n",
    "    print(f'optimizer: {cfg.optim.name}')\n",
    "    plist = [{'params': model.parameters(), 'lr': cfg.optim.lr, 'weight_decay': cfg.optim.weight_decay}]\n",
    "    optimizer = factory.get_optimizer(cfg.optim)(plist)\n",
    "\n",
    "    # get loss.\n",
    "    print(f'loss: {cfg.loss.name}')\n",
    "    loss = factory.get_loss(cfg.loss)\n",
    "\n",
    "    # get scheduler.\n",
    "    print(f'scheduler: {cfg.scheduler.name}')\n",
    "    scheduler = factory.get_scheduler(cfg.scheduler, optimizer)\n",
    "\n",
    "    # run model.\n",
    "    runner = Runner(cfg, model, loss, optimizer, scheduler, device, my_logger)\n",
    "    runner.train(dataset_train, dataset_valid, loader_train, loader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b702e336",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def submission():\n",
    "\n",
    "    args = util.get_args()\n",
    "    cfg = Config.fromfile(args.config)\n",
    "    cfg.fold = args.fold\n",
    "    cfg.working_dir = cfg.output_dir / cfg.version / str(cfg.fold)\n",
    "    print(f'version: {cfg.version}')\n",
    "    print(f'fold: {cfg.fold}')\n",
    "\n",
    "    # set logger.\n",
    "    my_logger = None\n",
    "\n",
    "    # set seed.\n",
    "    util.seed_everything(cfg.seed)\n",
    "\n",
    "    # get dataloader.\n",
    "    dataset_test, loader_test = factory.get_dataset_loader(cfg.test, [0])\n",
    "\n",
    "    # get model.\n",
    "    print(f'model: {cfg.model.name}')\n",
    "    model = factory.get_model(cfg.model)\n",
    "    device = factory.get_device(args.gpu)\n",
    "    model.cuda()\n",
    "    model.to(device)\n",
    "    if cfg.num_gpu>1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(cfg.working_dir / 'weight' / cfg.test.weight_name))\n",
    "\n",
    "    # get optimizer.\n",
    "    print(f'optimizer: {cfg.optim.name}')\n",
    "    plist = [{'params': model.parameters(), 'lr': cfg.optim.lr}]\n",
    "    optimizer = factory.get_optimizer(cfg.optim)(plist)\n",
    "\n",
    "    # get loss.\n",
    "    print(f'loss: {cfg.loss.name}')\n",
    "    loss = factory.get_loss(cfg.loss)\n",
    "\n",
    "    # get scheduler.\n",
    "    print(f'scheduler: {cfg.scheduler.name}')\n",
    "    scheduler = factory.get_scheduler(cfg.scheduler, optimizer)\n",
    "\n",
    "    # run model.\n",
    "    runner = Runner(cfg, model, loss, optimizer, scheduler, device, my_logger)\n",
    "    pred = runner.test(dataset_test, loader_test)\n",
    "    pred = np.clip(pred, 0.0, 3.0)\n",
    "    sub = pd.read_csv(cfg.test.data_path)\n",
    "    sub['target'] = pred\n",
    "    sub[['target']].to_csv(cfg.working_dir / f'sub_{cfg.version}.csv', index=False)\n",
    "    print('submission done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce6a6e6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def validation():\n",
    "\n",
    "    args = util.get_args()\n",
    "    cfg = Config.fromfile(args.config)\n",
    "    cfg.fold = args.fold\n",
    "    cfg.working_dir = cfg.output_dir / cfg.version / str(cfg.fold)\n",
    "    print(f'version: {cfg.version}')\n",
    "    print(f'fold: {cfg.fold}')\n",
    "\n",
    "    # set logger.\n",
    "    my_logger = None\n",
    "\n",
    "    # set seed.\n",
    "    util.seed_everything(cfg.seed)\n",
    "\n",
    "    # get dataloader.\n",
    "    folds = [fold for fold in range(cfg.n_fold) if cfg.fold != fold]\n",
    "    dataset_test, loader_test = factory.get_dataset_loader(cfg.valid, [cfg.fold])\n",
    "\n",
    "    # get model.\n",
    "    print(f'model: {cfg.model.name}')\n",
    "    model = factory.get_model(cfg.model)\n",
    "    device = factory.get_device(args.gpu)\n",
    "    model.cuda()\n",
    "    model.to(device)\n",
    "    if cfg.num_gpu>1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(cfg.working_dir / 'weight' / cfg.test.weight_name))\n",
    "\n",
    "    # get optimizer.\n",
    "    print(f'optimizer: {cfg.optim.name}')\n",
    "    plist = [{'params': model.parameters(), 'lr': cfg.optim.lr}]\n",
    "    optimizer = factory.get_optimizer(cfg.optim)(plist)\n",
    "\n",
    "    # get loss.\n",
    "    print(f'loss: {cfg.loss.name}')\n",
    "    loss = factory.get_loss(cfg.loss)\n",
    "\n",
    "    # get scheduler.\n",
    "    print(f'scheduler: {cfg.scheduler.name}')\n",
    "    scheduler = factory.get_scheduler(cfg.scheduler, optimizer)\n",
    "\n",
    "    # run model.\n",
    "    runner = Runner(cfg, model, loss, optimizer, scheduler, device, my_logger)\n",
    "    pred = runner.test(dataset_test, loader_test)\n",
    "    pred = np.clip(pred, 0.0, 3.0)\n",
    "    \n",
    "    sub = pd.read_csv(cfg.valid.data_path)\n",
    "    sub = sub[sub.fold.isin([cfg.fold])]\n",
    "    sub['pred'] = pred\n",
    "    \n",
    "    score = loss.calc_metrics(sub.pred.values, sub.target.values)\n",
    "    print(f'oof metric: {score:.4f}')\n",
    "    sub.to_csv(cfg.working_dir / f'oof_{cfg.version}_{score:.4f}.csv', index=False)\n",
    "    print(f'oof file was saved to: oof_{cfg.version}_{score:.4f}.csv')\n",
    "\n",
    "    util.line_notify(f'{cfg.version}\\ntrainning done.\\noof metric: {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b194a1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: CustomDataset_USBmicroBW\n"
     ]
    }
   ],
   "source": [
    "# set logger.\n",
    "cfg.logger.params.name = cfg.working_dir / f'history.csv'\n",
    "my_logger = util.CustomLogger(**cfg.logger.params)\n",
    "\n",
    "# set seed.\n",
    "util.seed_everything(cfg.seed)\n",
    "\n",
    "# get dataloader.\n",
    "print(f'dataset: {cfg.dataset_name}')\n",
    "folds = [fold for fold in range(cfg.n_fold) if cfg.fold != fold]\n",
    "dataset_train, loader_train = factory.get_dataset_loader(cfg.train, folds)\n",
    "dataset_valid, loader_valid = factory.get_dataset_loader(cfg.valid, [cfg.fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f457cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: NishikaCustomModelClass_USBmicroBW\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "# get model.\n",
    "print(f'model: {cfg.model.name}')\n",
    "model = factory.get_model(cfg.model)\n",
    "device = factory.get_device(args.gpu)\n",
    "model.cuda()\n",
    "model.to(device)\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da1fd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: AdamW\n"
     ]
    }
   ],
   "source": [
    "# get optimizer.\n",
    "print(f'optimizer: {cfg.optim.name}')\n",
    "plist = [{'params': model.parameters(), 'lr': cfg.optim.lr, 'weight_decay': cfg.optim.weight_decay}]\n",
    "optimizer = factory.get_optimizer(cfg.optim)(plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46263616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: CustomLossClassification\n"
     ]
    }
   ],
   "source": [
    "# get loss.\n",
    "print(f'loss: {cfg.loss.name}')\n",
    "loss = factory.get_loss(cfg.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19908e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler: CosineAnnealingLR\n"
     ]
    }
   ],
   "source": [
    "# get scheduler.\n",
    "print(f'scheduler: {cfg.scheduler.name}')\n",
    "scheduler = factory.get_scheduler(cfg.scheduler, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8deb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(loader_valid):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22a47fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img    = batch['image']\n",
    "target = batch['target']\n",
    "\n",
    "img   = img.to('cuda', dtype=torch.float)\n",
    "label = target.to('cuda', dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e99f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "003923fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1650,  0.0982],\n",
       "        [-0.0326, -0.1583],\n",
       "        [ 0.3918, -0.3617],\n",
       "        [ 0.3761, -0.1301],\n",
       "        [ 0.3321, -0.2154],\n",
       "        [ 0.4999, -0.0784],\n",
       "        [-0.0259, -0.2365],\n",
       "        [ 0.0850, -0.2814],\n",
       "        [ 0.1745,  0.1412],\n",
       "        [ 0.1013, -0.3381],\n",
       "        [-0.1586,  0.1679],\n",
       "        [-0.0196, -0.0884],\n",
       "        [ 0.1494, -0.3892],\n",
       "        [ 0.0996, -0.5150],\n",
       "        [-0.1473, -0.2289],\n",
       "        [ 0.0572, -0.1455]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbff11d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5910, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.calc_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model.\n",
    "runner = Runner(cfg, model, loss, optimizer, scheduler, device, my_logger)\n",
    "runner.train(dataset_train, dataset_valid, loader_train, loader_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
